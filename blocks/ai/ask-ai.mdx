---
title: Ask AI
---

## Overview

Interact with a large language model (LLM) using prompts that may be questions or actions such as summarizing information, generating ideas, or reasoning. It has the capability to understand additional context that can help refine its responses, and for more technical needs, It can be directed to provide structured output via predefined functions like OpenAI Functions or enabling JSON mode for LLM responses.

## Block Inputs

| Name             | Type     | Description                                                                                                                              |
| ---------------- | -------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| `question`       | string   | The core question you wish to ask the LLM. Clear and detailed questions yield better answers.                                            |
| `context`        | string   | Background information or specific situation related to the question. Enhances the relevance of the response.                            |
| `function`       | string   | Provide OpenAI functions to models from the GPT family. An OpenAI function can be easily created using the Define OpenAI Function block. |
| `model`          | selector | LLM Model to be used for inference. Can be one of the following supported models.                                                        |
| `json_mode`      | boolean  | When enabled, the response of the AI models are strictly JSON.                                                                           |
| `cache_response` | boolean  | When enabled, it saves you AI calls by returning the same response if the inputs to the LLM has not changed.                             |

## Block Outputs

| Name       | Type   | Description                                                    |
| ---------- | ------ | -------------------------------------------------------------- |
| `response` | string | LLMs Response. Can be a JSON string if `json_mode` is enabled. |

## Use Cases

1. **Generating Data:** Fill gaps within a piece of text using AI or generate relevant content of your choice based on a context and/or question.
2. **Additional Context:** Provides more background information for a complete answer, significantly enhancing the response's relevance.
3. **Specific Function Requirement:** Guides the response toward a particular objective or function, adding a layer of focus to the interaction with GPT models.
