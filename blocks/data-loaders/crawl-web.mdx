---
title: Crawl Web
---

## Overview

Crawls websites to extract (nested) links from a website. Methodically explore and document the web of links within a website, whether for analysis, SEO purposes, or competitive research.

## Block Inputs

| Name               | Type   | Default | Explanation                                                              |
| ------------------ | ------ | ------- | ------------------------------------------------------------------------ |
| `url`              | string |         | URL of the website to crawl.                                             |
| `depth`            | number | 1       | The number of layers to traverse in the crawl. Maximum value is 3        |
| `domain_whitelist` | list   |         | Limit the crawler to only visit links that belong to the set of domains. |

<Warning>
  Setting a depth of 3 for the web crawler might take longer processing times as
  it will crawl nested links with a link which may be exponential. Use it
  wisely.
</Warning>

<Info>
  The domain whitelist accepts domains such as "keyflow.space",
  "www.keyflow.space", or "docs.keyflow.space" etc. You can also write urls like
  "https://keyflow.space" and the crawler will automatically use ONLY the domain
  name in it.
</Info>

## Block Outputs

| Name       | Type      | Explanation                 |
| ---------- | --------- | --------------------------- |
| `url_list` | string[ ] | List of all the URLs found. |

## Use Cases

1. **Link Collection:** Ideal for compiling a list of all links on a specific website.
2. **Website Structure Analysis:** Helps in understanding the interconnectivity of different pages on a website.
3. **SEO and Web Audit:** Useful for a comprehensive check of website links for SEO or general analysis.
4. **Competitive Insight:** Assists in mapping the link structure of competitor or own websites to gauge content references.
